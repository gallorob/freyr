{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "# df = pd.read_csv('./experiments/full_comparable_results.csv')\n",
    "df = pd.read_csv('./experiments/full_freyr_results.csv')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# from scipy.stats import wilcoxon\n",
    "# import numpy as np\n",
    "#\n",
    "# for tcase in df['test_case'].unique():\n",
    "# \tfor intent_llm in ['command-r', 'qwen2.5', 'llama3.1']:\n",
    "# \t\tsub_df_a = df.loc[(df['bootstrap'] == True) &\n",
    "# \t\t                (df['test_case'] == tcase) &\n",
    "# \t\t                (df['intent_llm'] == intent_llm) &\n",
    "# \t\t                (df['params_llm'] == intent_llm) &\n",
    "# \t\t                (df['mode'] == 'freyr')].groupby('run_n')\n",
    "# \t\tsub_df_b = df.loc[(df['bootstrap'] == True) &\n",
    "# \t\t                  (df['test_case'] == tcase) &\n",
    "# \t\t                  (df['intent_llm'] == intent_llm) &\n",
    "# \t\t                (df['mode'] == 'tool')].groupby('run_n')\n",
    "# \t\tsuccess_a = sub_df_a['valid_domain'].sum().tolist()\n",
    "# \t\tsuccess_b = sub_df_b['valid_domain'].sum().tolist()\n",
    "# \t\t_, pval = wilcoxon(success_a, success_b, correction=True)\n",
    "# \t\tif pval < 0.05: print(tcase, intent_llm)\n"
   ],
   "id": "cf7163e9cb73753a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from scipy.stats import wilcoxon\n",
    "import numpy as np\n",
    "\n",
    "tcases, intents, params = [], [], []\n",
    "in_tks, out_tks, t_step = [], [], []\n",
    "\n",
    "for tcase in df['test_case'].unique():\n",
    "\tfor intent_llm_a in ['command-r', 'qwen2.5', 'llama3.1']:\n",
    "\t\tfor params_llm_a in ['command-r', 'qwen2.5', 'llama3.1']:\n",
    "\t\t\tif intent_llm_a != params_llm_a:\n",
    "\t\t\t\tsub_df_a = df.loc[(df['bootstrap'] == True) &\n",
    "\t\t\t\t                (df['test_case'] == tcase) &\n",
    "\t\t\t\t                (df['intent_llm'] == intent_llm_a) &\n",
    "\t\t\t\t                (df['params_llm'] == params_llm_a)].groupby('run_n')\n",
    "\t\t\t\tin_tks_a = sub_df_a['in_tks'].mean().tolist()\n",
    "\t\t\t\tout_tks_a = sub_df_a['out_tks'].mean().tolist()\n",
    "\t\t\t\tt_step_a = sub_df_a['t_step'].mean().tolist()\n",
    "\t\t\t\tsuccess_a = sub_df_a['valid_domain'].sum().tolist()\n",
    "\t\t\t\tin_tks_pvals, out_tks_pvals, t_step_pvals = [], [], []\n",
    "\t\t\t\tsuccess_pvals = []\n",
    "\t\t\t\tfor intent_llm_b in ['command-r', 'qwen2.5', 'llama3.1']:\n",
    "\t\t\t\t\tfor params_llm_b in ['command-r', 'qwen2.5', 'llama3.1']:\n",
    "\t\t\t\t\t\tif intent_llm_a != intent_llm_b and params_llm_a != params_llm_b:\n",
    "\t\t\t\t\t\t\tsub_df_b = df.loc[(df['bootstrap'] == True) &\n",
    "\t\t\t\t\t\t\t                (df['test_case'] == tcase) &\n",
    "\t\t\t\t\t\t\t                (df['intent_llm'] == intent_llm_b) &\n",
    "\t\t\t\t\t\t\t                (df['params_llm'] == params_llm_b)].groupby('run_n')\n",
    "\t\t\t\t\t\t\tin_tks_b = sub_df_b['in_tks'].mean().tolist()\n",
    "\t\t\t\t\t\t\tout_tks_b = sub_df_b['out_tks'].mean().tolist()\n",
    "\t\t\t\t\t\t\tt_step_b = sub_df_b['t_step'].mean().tolist()\n",
    "\t\t\t\t\t\t\tsuccess_b = sub_df_b['valid_domain'].sum().tolist()\n",
    "\n",
    "\t\t\t\t\t\t\t_, in_tks_pval = wilcoxon(in_tks_a, in_tks_b, correction=True)\n",
    "\t\t\t\t\t\t\t_, out_tks_pval = wilcoxon(out_tks_a, out_tks_b, correction=True)\n",
    "\t\t\t\t\t\t\t_, t_step_pval = wilcoxon(t_step_a, t_step_b, correction=True)\n",
    "\t\t\t\t\t\t\t_, success_pval = wilcoxon(success_a, success_b, correction=True, zero_method='zsplit')\n",
    "\t\t\t\t\t\t\tsuccess_pvals.append(success_pval)\n",
    "\t\t\t\t\t\t\tin_tks_pvals.append(in_tks_pval)\n",
    "\t\t\t\t\t\t\tout_tks_pvals.append(out_tks_pval)\n",
    "\t\t\t\t\t\t\tt_step_pvals.append(t_step_pval)\n",
    "\t\t\t\tif np.all(np.asarray(in_tks_pvals) < 0.05): print(tcase, intent_llm_a, params_llm_a, 'Tokens_in', in_tks_pvals)\n",
    "\t\t\t\tif np.all(np.asarray(out_tks_pvals) < 0.05): print(tcase, intent_llm_a, params_llm_a, 'Tokens_out', out_tks_pvals)\n",
    "\t\t\t\tif np.all(np.asarray(t_step_pvals) < 0.05): print(tcase, intent_llm_a, params_llm_a, 'Time', t_step_pvals)\n",
    "\t\t\t\tif np.all(np.asarray(success_pvals) < 0.05): print(tcase, intent_llm_a, params_llm_a, 'Valid Domain', success_pvals)\n"
   ],
   "id": "373db7766fe09557",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from scipy.stats import wilcoxon\n",
    "import numpy as np\n",
    "\n",
    "tcases, intents, params = [], [], []\n",
    "in_tks, out_tks, t_step = [], [], []\n",
    "\n",
    "for tcase in df['test_case'].unique():\n",
    "\tfor intent_llm_a in ['command-r', 'qwen2.5', 'llama3.1', 'gemma2']:\n",
    "\t\tfor params_llm_a in ['command-r', 'qwen2.5', 'llama3.1', 'gemma2']:\n",
    "\t\t\tif intent_llm_a != params_llm_a and (intent_llm_a == 'gemma2' or params_llm_a == 'gemma2'):\n",
    "\t\t\t\tsub_df_a = df.loc[(df['bootstrap'] == True) &\n",
    "\t\t\t\t                (df['test_case'] == tcase) &\n",
    "\t\t\t\t                (df['intent_llm'] == intent_llm_a) &\n",
    "\t\t\t\t                (df['params_llm'] == params_llm_a)].groupby('run_n')\n",
    "\t\t\t\tin_tks_a = sub_df_a['in_tks'].mean().tolist()\n",
    "\t\t\t\tout_tks_a = sub_df_a['out_tks'].mean().tolist()\n",
    "\t\t\t\tt_step_a = sub_df_a['t_step'].mean().tolist()\n",
    "\t\t\t\tsuccess_a = sub_df_a['valid_domain'].sum().tolist()\n",
    "\t\t\t\tin_tks_pvals, out_tks_pvals, t_step_pvals = [], [], []\n",
    "\t\t\t\tsuccess_pvals = []\n",
    "\t\t\t\tfor intent_llm_b in ['command-r', 'qwen2.5', 'llama3.1', 'gemma2']:\n",
    "\t\t\t\t\tfor params_llm_b in ['command-r', 'qwen2.5', 'llama3.1', 'gemma2']:\n",
    "\t\t\t\t\t\tif intent_llm_a != intent_llm_b and intent_llm_b != params_llm_b and (intent_llm_a == 'gemma2' or params_llm_a == 'gemma2'):\n",
    "\t\t\t\t\t\t\tsub_df_b = df.loc[(df['bootstrap'] == True) &\n",
    "\t\t\t\t\t\t\t                (df['test_case'] == tcase) &\n",
    "\t\t\t\t\t\t\t                (df['intent_llm'] == intent_llm_b) &\n",
    "\t\t\t\t\t\t\t                (df['params_llm'] == params_llm_b)].groupby('run_n')\n",
    "\t\t\t\t\t\t\tin_tks_b = sub_df_b['in_tks'].mean().tolist()\n",
    "\t\t\t\t\t\t\tout_tks_b = sub_df_b['out_tks'].mean().tolist()\n",
    "\t\t\t\t\t\t\tt_step_b = sub_df_b['t_step'].mean().tolist()\n",
    "\t\t\t\t\t\t\tsuccess_b = sub_df_b['valid_domain'].sum().tolist()\n",
    "\n",
    "\t\t\t\t\t\t\t_, in_tks_pval = wilcoxon(in_tks_a, in_tks_b, correction=True)\n",
    "\t\t\t\t\t\t\t_, out_tks_pval = wilcoxon(out_tks_a, out_tks_b, correction=True)\n",
    "\t\t\t\t\t\t\t_, t_step_pval = wilcoxon(t_step_a, t_step_b, correction=True)\n",
    "\t\t\t\t\t\t\t_, success_pval = wilcoxon(success_a, success_b, correction=True, zero_method='zsplit')\n",
    "\t\t\t\t\t\t\tsuccess_pvals.append(success_pval)\n",
    "\t\t\t\t\t\t\tin_tks_pvals.append(in_tks_pval)\n",
    "\t\t\t\t\t\t\tout_tks_pvals.append(out_tks_pval)\n",
    "\t\t\t\t\t\t\tt_step_pvals.append(t_step_pval)\n",
    "\t\t\t\tif np.all(np.asarray(in_tks_pvals) < 0.05): print(tcase, intent_llm_a, params_llm_a, 'Tokens_in', in_tks_pvals)\n",
    "\t\t\t\tif np.all(np.asarray(out_tks_pvals) < 0.05): print(tcase, intent_llm_a, params_llm_a, 'Tokens_out', out_tks_pvals)\n",
    "\t\t\t\tif np.all(np.asarray(t_step_pvals) < 0.05): print(tcase, intent_llm_a, params_llm_a, 'Time', t_step_pvals)\n",
    "\t\t\t\tif np.all(np.asarray(success_pvals) < 0.05): print(tcase, intent_llm_a, params_llm_a, 'Valid Domain', success_pvals)\n"
   ],
   "id": "4b9daa581af119df",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# from scipy.stats import wilcoxon\n",
    "# from itertools import combinations\n",
    "# import numpy as np\n",
    "#\n",
    "#\n",
    "# full_stats = pd.DataFrame()\n",
    "#\n",
    "# for tcase in df['test_case'].unique():\n",
    "# \ttoks_in, toks_out, ts = [], [], []\n",
    "# \tnames = []\n",
    "# \t# for llm in ['command-r', 'llama3.1', 'qwen2.5']:\n",
    "# \t# \tfor mode in ['freyr', 'tool']:\n",
    "# \tfor intent_llm in df['intent_llm'].unique():\n",
    "# \t\tfor params_llm in df['params_llm'].unique():\n",
    "# \t\t\tsub_df = df.loc[(df['bootstrap'] == True) &\n",
    "# \t\t\t                (df['test_case'] == tcase) &\n",
    "# \t\t\t                # (df['intent_llm'] == llm) &\n",
    "# \t\t\t                # (df['mode'] == mode)].groupby('run_n')\n",
    "# \t\t\t                (df['intent_llm'] == intent_llm) &\n",
    "# \t\t\t                (df['params_llm'] == params_llm)].groupby('run_n')\n",
    "# \t\t\ttoks_in.append(sub_df['in_tks'].mean())\n",
    "# \t\t\ttoks_out.append(sub_df['out_tks'].mean())\n",
    "# \t\t\tts.append(sub_df['t_step'].mean())\n",
    "# \t\t\t# names.append(f'{tcase}-{llm}-{mode}')\n",
    "# \t\t\tnames.append(f'{tcase}-{intent_llm}-{params_llm}')\n",
    "#\n",
    "# \tfor name, arr in zip(['input_tokens', 'output_tokes', 'time'],\n",
    "# \t                     [toks_in, toks_out, ts]):\n",
    "# \t\tresults = []\n",
    "#\n",
    "# \t\t# Pairwise comparisons\n",
    "# \t\tfor (i, s1), (j, s2) in combinations(enumerate(arr), 2):\n",
    "# \t\t\ttry:\n",
    "# \t\t\t\tif 'gemma2:27b' in names[i] or 'gemma2:27b' in names[j]:\n",
    "# \t\t\t\t\tcontinue\n",
    "# \t\t\t\tstat, p_value = wilcoxon(s1, s2, correction=True)\n",
    "# \t\t\t\tresults.append((names[i], names[j], name, stat, p_value))\n",
    "#\n",
    "# \t\t\t\tif p_value >= 0.05:\n",
    "# \t\t\t\t\tprint(name, names[i], names[j], p_value)\n",
    "# \t\t\texcept ValueError:\n",
    "# \t\t\t\tresults.append((names[i], names[j], name, np.nan, 0.0))\n",
    "#\n",
    "# \t\t# # Bonferroni correction\n",
    "# \t\t# n_tests = len(results)\n",
    "# \t\t# corrected_results = [\n",
    "# \t\t#     (name1, name2, stat, min(p_value * n_tests, 1))  # Adjust p-value and cap at 1\n",
    "# \t\t#     for name1, name2, stat, p_value in results\n",
    "# \t\t# ]\n",
    "#\n",
    "# \t\t# Create a DataFrame for better visualization\n",
    "# \t\tdf_results = pd.DataFrame(results, columns=[\"Series 1\", \"Series 2\", \"Target\", \"Statistic\", \"Corrected p-value\"])\n",
    "# \t\tfull_stats = pd.concat([full_stats, df_results], ignore_index=True)\n",
    "#\n",
    "# full_stats.to_csv(f'./experiments/stat_analysis_freyronly.csv', index=False)"
   ],
   "id": "84a7f4e47ed28884",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# import numpy as np\n",
    "# from typing import Tuple\n",
    "#\n",
    "#\n",
    "# table = pd.DataFrame()\n",
    "#\n",
    "# def get_credible_interval(s: pd.Series) -> Tuple[float, float]:\n",
    "# \tm, c, s = s.mean(), s.count(), s.std()\n",
    "# \treturn m + 1.96 * s / np.sqrt(c), m - 1.96 * s / np.sqrt(c)\n",
    "#\n",
    "# for tcase in sorted(df['test_case'].unique()):\n",
    "# \t# for llm in ['command-r', 'llama3.1', 'qwen2.5']:\n",
    "# \t# \tfor mode in ['freyr', 'tool']:\n",
    "# \tfor intent_llm in df['intent_llm'].unique():\n",
    "# \t\tfor params_llm in df['params_llm'].unique():\n",
    "# \t\t\t# vs = df.loc[(df['bootstrap'] == True) & (df['test_case'] == tcase) & (df['intent_llm'] == llm) & (df['mode'] == mode)].groupby('run_n')\n",
    "# \t\t\tvs = df.loc[(df['bootstrap'] == True) & (df['test_case'] == tcase) & (df['intent_llm'] == intent_llm) & (df['params_llm'] == params_llm)].groupby('run_n')\n",
    "#\n",
    "# \t\t\tin_tks = vs['in_tks'].mean()\n",
    "# \t\t\tout_tks = vs['out_tks'].mean()\n",
    "# \t\t\ttime = vs['t_step'].mean()\n",
    "#\n",
    "# \t\t\trow = pd.DataFrame({\n",
    "# \t\t\t\t'test case': tcase,\n",
    "# \t\t\t\t'intent_llm': intent_llm,\n",
    "# \t\t\t\t# 'llm': llm,\n",
    "# \t\t\t\t'params_llm': params_llm,\n",
    "# \t\t\t\t# 'mode': mode,\n",
    "# \t\t\t\t'in_tks': f\"${in_tks.mean():.1f} \\pm {get_credible_interval(in_tks)[0] - in_tks.mean():.1f}$\",\n",
    "# \t\t\t\t'out_tks': f\"${out_tks.mean():.1f} \\pm {get_credible_interval(out_tks)[0] - out_tks.mean():.1f}$\",\n",
    "# \t\t\t\t'time': f\"${time.mean():.1f} \\pm {get_credible_interval(time)[0] - time.mean():.1f}$\"\n",
    "# \t\t\t}, index=[0])\n",
    "#\n",
    "# \t\t\ttable = pd.concat([table, row], ignore_index=True)"
   ],
   "id": "dad4ee8f32032b35",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# from tabulate import tabulate\n",
    "#\n",
    "# latex_table = tabulate(\n",
    "#     table, tablefmt='latex_raw', showindex=False\n",
    "# )\n",
    "# with open(f'./experiments/freyr_table.tex', 'w') as f:\n",
    "# \tf.write(latex_table)"
   ],
   "id": "4a595c4cf59e0341",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "f6e804beaa62d93",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "f7526496e3e4a25b",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
